---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am currently a Postdoctoral Fellow (Assistant Research Fellow) in the Department of Automation at Tsinghua University, working under the supervision of Professor Qionghai Dai. I received my Ph.D. degree in Engineering from Tsinghua University in 2024.

I am dedicated to the interdisciplinary frontier of **AI for Astronomy** and **Computational Astronomical Imaging**, focusing on mitigating fundamental physical problems such as optical aberration, atmospheric turbulence, and photon noise. My research vision is to architect AI-powered instruments for next-generation observational astronomy. My work has been featured as first-author publications in *Nature*, *Science*, and *Nature Photonics*. I am also serving as a reviewer for *Nature*, *IEEE TCSVT*, *Optica*, *Scientific Reports* and *Optics Express*. Now, I'm serving as an Executive Editor for the special issue 'Intelligent Optical Astronomical Observation Technology' in *Laser & Optoelectronics Progress*.



# üìù Representative Publications 
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Science 2026</div><img src='2.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Deeper detection limits in astronomical imaging using self-supervised spatiotemporal denoising](https://www.nature.com/articles/s41566-024-01466-3)

**Yuduo Guo‚Ä†**, Hao Zhang‚Ä†, Mingyu Li‚Ä†, Fujiang Yu, Yunjing Wu, Yuhan Hao, Song Huang, Yongming Liang, Xiaojing Lin, Xinyang Li, Jiamin Wu*, Zheng Cai*, Qionghai Dai*


[**Abstract**](https://scholar.google.co.jp/scholar?q=direct+observation+of+atmospheric+turbulence&hl=zh-CN&as_sdt=0&as_vis=1&oi=scholart) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>


-Accepted. To be updated.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Nature Photonics 2024</div><img src='images/NP.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Direct observation of atmospheric turbulence with a video-rate wide-field wavefront sensor](https://www.nature.com/articles/s41566-024-01466-3)

**Yuduo Guo‚Ä†**, Yuhan Hao‚Ä†, Sen Wan‚Ä†, Hao Zhang, Laiyu Zhu, Yi Zhang, Jiamin Wu*, Qionghai Dai*, Lu Fang*

[**Abstract**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=VaGAePwAAAAJ&citation_for_view=VaGAePwAAAAJ:9yKSN-GCB0IC) <strong><span class='show_paper_citations' data='VaGAePwAAAAJ:9yKSN-GCB0IC'></span></strong>


- Turbulence is a complex and chaotic state of fluid motion. **Atmospheric turbulence** within the Earth‚Äôs atmosphere poses fundamental challenges for applications such as remote sensing, free-space optical communications and astronomical observation due to its rapid evolution across temporal and spatial scales. Conventional methods for studying atmospheric turbulence face hurdles in capturing the wide-field distribution of turbulence due to its transparency and **anisoplanatism**. Here we develop **a light-field-based plug-and-play wide-field wavefront sensor (WWS)**, facilitating the direct observation of atmospheric turbulence over **1,100‚Äâarcsec** at 30‚ÄâHz. The experimental measurements agreed with the von K√°rm√°n turbulence model, further verified using a differential image motion monitor. Attached to an 80‚Äâcm telescope, our WWS enables clear turbulence profiling of three layers below an altitude of 750‚Äâm and high-resolution aberration-corrected imaging without additional deformable mirrors. The WWS also enables prediction of the evolution of turbulence dynamics within **33‚Äâms** using a convolutional recurrent neural network with wide-field measurements, leading to more accurate pre-compensation of turbulence-induced errors during free-space optical communication. Wide-field sensing of dynamic turbulence wavefronts provides new opportunities for studying the evolution of turbulence in the broad field of atmospheric optics.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Nature Photonics 2024</div><img src='images/NP.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[An integrated ima ging sensor for aberration-corrected 3D photography](https://www.nature.com/articles/s41586-022-05306-8)

Jiamin Wu‚Ä†, **Yuduo Guo‚Ä†**, Chao Deng‚Ä†, Anke Zhang, Hui Qiao, Zhi Lu, Jiachen Xie, Lu Fang*, Qionghai Dai*

- <span style="color: #d9534f; font-weight: bold;">[ESI Highly Cited Paper]</span>

[**Abstract**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=VaGAePwAAAAJ&citation_for_view=VaGAePwAAAAJ:u-x6o8ySG0sC) <strong><span class='show_paper_citations' data='VaGAePwAAAAJ:u-x6o8ySG0sC'></span></strong>


- Planar digital image sensors facilitate broad applications in a wide range of areas, and the number of pixels has scaled up rapidly in recent years. However, the practical performance of imaging systems is fundamentally limited by spatially nonuniform optical aberrations originating from imperfect lenses or environmental disturbances. Here we propose an **integrated scanning light-field imaging sensor**, termed a **meta-imaging sensor**, to achieve high-speed aberration-corrected three-dimensional photography for universal applications without additional hardware modifications. Instead of directly detecting a two-dimensional intensity projection, the meta-imaging sensor captures extra-fine four-dimensional light-field distributions through a vibrating coded microlens array, enabling flexible and precise synthesis of complex-field-modulated images in post-processing. Using the sensor, we achieve high-performance photography up to a **gigapixel with a single spherical lens** without a data prior, leading to **orders-of-magnitude reductions in system capacity and costs for optical imaging**. Even in the presence of dynamic atmosphere turbulence, the meta-imaging sensor enables multisite aberration correction across **1,000‚Äâarcseconds on an 80-centimetre ground-based telescope** without reducing the acquisition speed, paving the way for high-resolution synoptic sky surveys. Moreover, high-density accurate depth maps can be retrieved simultaneously, facilitating diverse applications from autonomous driving to industrial inspections.
</div>
</div>

- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**

# üéñ Honors and Awards
- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# üìñ Educations
- *2019.06 - 2022.04 (now)*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2015.09 - 2019.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# üí¨ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)

# üíª Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.
